{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA UPLOADING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Folder Path and Initializing Empty Dictionary to Store DataFrames\n",
    "folder_path = \"E:/Documents/Data Analyst Roadmap/SQL/SQL Projects/Bellabeat Case Study/archive/mturkfitbit_export_4.12.16-5.12.16/Fitabase Data 4.12.16-5.12.16\"\n",
    "df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Loop to Download All CSV Diles Into Pandas DataFrames\n",
    "for filename in os.listdir(folder_path):\n",
    "    try:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df_name = filename.replace(\".csv\", \"\")\n",
    "        df[df_name] = pd.read_csv(file_path)\n",
    "        print(f\"Loaded: {filename} --> {df_name} (shape: {df[df_name].shape})\")\n",
    "    except:\n",
    "        print(f\"Failed to load: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase First 5 Rows of Data to Ensure Proper Upload\n",
    "for name, data in df.items():\n",
    "    print(f\"\\n{name} (first 5 rows):\")\n",
    "    display(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Data Structure of Each DataFrame\n",
    "for name, data in df.items():\n",
    "    print(f\"\\n{name} (Data Structure):\")\n",
    "    display(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERAL DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Rows With All NA Values and Duplicates\n",
    "for name, data in df.items():\n",
    "    original_shape = data.shape\n",
    "    data.dropna(axis = \"index\", how = \"all\", inplace = True, ignore_index = False)\n",
    "    data.drop_duplicates(inplace = True)\n",
    "    print(f\"{name} -- Before Cleaning {original_shape} -> After cleaning: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILTERING DATASET TO MEET KPIs\n",
    "- I will be using dailyActivity_merged, dailyCalories_merged, sleepDay_merged, weightLogInfo_merged, and minuteMETsNarrow_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at dailyActivity \n",
    "dailyActivity = df[\"dailyActivity_merged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Redundant Columns From DataFrames \n",
    "dailyActivity.drop(['TotalDistance', 'TrackerDistance', 'VeryActiveDistance', 'ModeratelyActiveDistance', 'LightActiveDistance', 'SedentaryActiveDistance', 'LoggedActivitiesDistance'], \n",
    "                   axis = 1, inplace = True, errors = \"ignore\") # axis = 1 to drop columns, inplace = True to directly change the DataFrame \n",
    "\n",
    "# Setting ActivityDate to DateTime Format\n",
    "dailyActivity[\"ActivityDate\"] = pd.to_datetime(dailyActivity[\"ActivityDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check If Update Was Successful\n",
    "dailyActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at sleepDay_merged\n",
    "sleepDay = df[\"sleepDay_merged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping TotalSleepRecords\n",
    "sleepDay.drop([\"TotalSleepRecords\"], axis = 1, inplace = True, errors = \"ignore\")\n",
    "\n",
    "# Adding TotalHoursAsleep and TotalHoursInBed\n",
    "sleepDay['TotalHoursAsleep'] = (sleepDay['TotalMinutesAsleep'] / 60).round(2)\n",
    "sleepDay['TotalHoursInBed'] = (sleepDay['TotalTimeInBed'] / 60).round(2)\n",
    "\n",
    "\n",
    "# Setting SleepDay to DateTime Format\n",
    "sleepDay[\"SleepDay\"] = pd.to_datetime(sleepDay[\"SleepDay\"], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Check to See if Update was Successful\n",
    "sleepDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at dailyCalories_merged\n",
    "dailyCalories = df[\"dailyCalories_merged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting ActivityDay to DateTime Format\n",
    "dailyCalories[\"ActivityDay\"] = pd.to_datetime(dailyCalories[\"ActivityDay\"])\n",
    "\n",
    "# Check if Changes Were Successful\n",
    "dailyCalories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at weightLogInfo_merged\n",
    "weightLogInfo = df[\"weightLogInfo_merged\"]\n",
    "\n",
    "# Dropping Fat, IsManualReport, LogId Columns as they Do Not Provide Insightful Data For Our Usecase\n",
    "weightLogInfo.drop([\"Fat\", \"IsManualReport\", \"LogId\"], axis = 1, inplace = True, errors = \"ignore\")\n",
    "\n",
    "# Round WegithKg, WeightPounds, and BMI to 2 Decimals For Cleaner Data\n",
    "weightLogInfo[[\"WeightKg\", \"WeightPounds\", \"BMI\"]] = weightLogInfo[[\"WeightKg\", \"WeightPounds\", \"BMI\"]].round(2)\n",
    "\n",
    "# Change Date to DateTime Format\n",
    "weightLogInfo[\"Date\"] = pd.to_datetime(weightLogInfo[\"Date\"], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "weightLogInfo[\"Date\"] = weightLogInfo[\"Date\"].dt.date\n",
    "\n",
    "# Check if Changes Were Successful\n",
    "weightLogInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at minuteMETsNarrow_merged -- Will be used for a heatmap categorized by day and the time of day\n",
    "METS = df[\"minuteMETsNarrow_merged\"].copy(deep=True)\n",
    "\n",
    "# Convert ActivityMinute to DateTime\n",
    "METS[\"ActivityMinute\"] = pd.to_datetime(METS[\"ActivityMinute\"], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Add a New Column Called \"Day\" to Show What Day of the Week the Date is\n",
    "METS[\"Day\"] = METS[\"ActivityMinute\"].dt.day_name()\n",
    "\n",
    "# Add a New Column Called \"Hour\" to Show What Hour (24 Hour Clock) the METs was Tracked\n",
    "METS[\"Hour\"] = METS[\"ActivityMinute\"].dt.hour\n",
    "\n",
    "# Convert \"Activity Minute\" to Only Include the Date and Not the Hour\n",
    "METS[\"ActivityMinute\"] = METS[\"ActivityMinute\"].dt.date\n",
    "\n",
    "# Reorder columns and Rename \"ActivityMinute\" to \"Date\"\n",
    "METS = METS[[\"Id\", \"ActivityMinute\", \"Day\", \"Hour\", \"METs\"]]\n",
    "METS = METS.rename(columns = {\"ActivityMinute\":\"Date\"})\n",
    "\n",
    "# Check to see if the changes were successful\n",
    "METS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at minuteMETsNarrow_merged -- This time used for finding AVG METs per time of day\n",
    "METS_avg = df[\"minuteMETsNarrow_merged\"].copy(deep=True)\n",
    "\n",
    "# Convert ActivityMinute to DateTime\n",
    "METS_avg[\"ActivityMinute\"] = pd.to_datetime(METS_avg[\"ActivityMinute\"], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "# Convert ActivityMinute to Hours\n",
    "METS_avg['ActivityMinute'] = METS_avg['ActivityMinute'].dt.hour\n",
    "\n",
    "# Dropping Id, ActivityMinute, and Day\n",
    "METS_avg = METS_avg.drop(['Id'], axis = 1)\n",
    "\n",
    "# Renaming ActivityMinute column to Hour of Day\n",
    "METS_avg = METS_avg.rename(columns={'ActivityMinute':'Hour_of_Day'})\n",
    "\n",
    "# Grouping By Day, Finding the Average Value of METs\n",
    "METS_avg = METS_avg.groupby(['Hour_of_Day']).agg({'METs':'mean'})\n",
    "METS_avg[\"METs\"] = METS_avg[\"METs\"].round(2) # Rounding to two decimals\n",
    "\n",
    "# Display\n",
    "METS_avg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPLOAD RELEVANT DATAFRAMES INTO CSV FILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a List to Iterate Over a For Loop\n",
    "dataframes = [dailyActivity, dailyCalories, sleepDay, weightLogInfo, METS, METS_avg]\n",
    "names = ['dailyActivity', 'dailyCalories', 'sleepDay', 'weightLogInfo', 'METS_3', 'METS_avg']\n",
    "\n",
    "for i, name in zip(dataframes, names):\n",
    "    i.to_csv(f\"{name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
